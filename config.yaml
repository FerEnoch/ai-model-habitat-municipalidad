# PDF Data Extraction Configuration

# fine_tunning:
#   training_data: "dataset/"
#   epochs: 3
#   batch_size: 4
#   learning_rate: 0.0001
#   input_prompt_file: "prompts/ft_input_prompt.md"

file_processing:
  input_folder: "dataset/"
  output_file: "dataset.json"
  supported_formats: ["pdf"]
  ocr_method: "tesseract"
  max_concurrent_tasks: 4  # Number of concurrent OCR tasks (workers)
  test_limit: 2  # Number of files to process for testing (null for all files)


ollama:
  model: "resolution-summarizer"
  temperature: 0.25  # (Creativity vs Consistency) - 0.3-0.5: Good balance for factual summaries
  top_k: 40        # (Token Selection Pool) - 20-50 for balamce and more diverse token selection
  top_p: 0.9       # (Cumulative Probability) - 0.7-0.9: Balanced - Better balance of creativity/consistency
  format: ""       # Plain text for summaries

### phi3:latest (LIGHTWEIGHT ALTERNATIVE)
# ollama:
#   model: "phi3:latest"
#   temperature: 0.4
#   top_k: 50
#   top_p: 0.9
#   format: ""

### nuextract:latest (STRUCTURED DATA FOCUS)
# ollama:
#   model: "nuextract:latest"
#   temperature: 0.2
#   top_k: 20
#   top_p: 0.8
#   format: "json"
# extraction:
#   required_fields:
#     - "numero_resolucion"
#     - "fecha_resolucion"
#     - "ente_emisor"
#     - "descripcion"
#     - "tema"

logging:
  level: "INFO"
  format: "%(asctime)s - %(levelname)s - %(message)s"

timezone:
  name: "America/Argentina/Buenos_Aires"